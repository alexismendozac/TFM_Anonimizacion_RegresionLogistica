
# TFM Â· AnonimizaciÃ³n y RegresiÃ³n LogÃ­stica para DetecciÃ³n de Fraude

Este repositorio contiene el desarrollo completo de un Trabajo de Fin de MÃ¡ster (TFM) centrado en tÃ©cnicas de anonimizaciÃ³n de datos y su impacto en modelos de regresiÃ³n logÃ­stica aplicados a la detecciÃ³n de fraude.

---


### ğŸ“„ Documento del Trabajo Final de MÃ¡ster

El informe completo del TFM estÃ¡ disponible en el siguiente enlace:

ğŸ“ [TFM - AnonimizaciÃ³n y Cumplimiento del GDPR con Modelos LLM](https://drive.google.com/drive/folders/1bU1SSvt7IW3EzleY2cjp6QdY42P9pYrP)

Incluye fundamentos legales, tÃ©cnicas avanzadas de protecciÃ³n de datos (k-anonimato, l-diversidad, privacidad diferencial) y evaluaciÃ³n empÃ­rica con modelos de clasificaciÃ³n (Random Forest, XGBoost, RegresiÃ³n LogÃ­stica).


---

### ğŸ“‚ Estructura del Proyecto

```
TFM_Anonimizacion_RegresionLogistica/
â”‚
â”œâ”€â”€ dataset/                         # Carpeta reservada para el dataset local (excluido del repo)
â”‚
â”œâ”€â”€ notebooks/                       # AnÃ¡lisis y visualizaciÃ³n en Jupyter
â”‚   â”œâ”€â”€ notebook_analisis_privacidad-utilidad_anonimizacion.ipynb
â”‚   â”œâ”€â”€ notebook_deteccion_fraude_basico.ipynbgit add .git add .
â”‚   â””â”€â”€ notebook_EDA_anonimizacion_LLMs.ipynb
â”‚
â”œâ”€â”€ src/                             # Scripts de anÃ¡lisis y modelos
â”‚   â”œâ”€â”€ comparativa_modelos_RL.py
â”‚   â”œâ”€â”€ eda_anonimizacion_fraud_detection.py
â”‚   â””â”€â”€ eda_anonimizacion_modular.py
â”‚
â”œâ”€â”€ venv/                            # Entorno virtual (ignorado por Git)
â”‚
â”œâ”€â”€ requirements.txt                # LibrerÃ­as necesarias
â”œâ”€â”€ .gitignore                      # Archivos ignorados (venv, dataset, logs, etc.)
â”œâ”€â”€ .gitattributes
â””â”€â”€ README.md                       # Este archivo
```

---

### ğŸ“ Dataset

ğŸ” **Por motivos de privacidad, el dataset no se encuentra en este repositorio.**  
Puedes descargarlo desde el siguiente enlace de Google Drive:

ğŸ“ [`anonimizacion_datos.csv`](https://drive.google.com/drive/u/0/folders/15hNc2cTtTDilX9EkOmLgEerf5v53ZScB)

Una vez descargado, colÃ³calo en la siguiente ruta local:

```
dataset/anonimizacion_datos.csv
```

> âœ… Este archivo estÃ¡ incluido en `.gitignore` para evitar su exposiciÃ³n pÃºblica.

---

### ğŸ“Š Contenido de los notebooks

- `notebook_EDA_anonimizacion_LLMs.ipynb`  
  ExploraciÃ³n de datos y visualizaciÃ³n con soporte de LLMs para comprensiÃ³n semÃ¡ntica de variables.

- `notebook_deteccion_fraude_basico.ipynb`  
  Modelo base de regresiÃ³n logÃ­stica sobre datos sin anonimizar.

- `notebook_analisis_privacidad-utilidad_anonimizacion.ipynb`  
  AnÃ¡lisis de cÃ³mo la anonimizaciÃ³n afecta la precisiÃ³n del modelo, con mÃ©tricas de privacidad y utilidad.

---

### ğŸ§  Scripts principales (`/src`)

- `eda_anonimizacion_modular.py`  
  ExploraciÃ³n de datos modularizada y reutilizable para mÃºltiples escenarios de anonimizaciÃ³n.

- `eda_anonimizacion_fraud_detection.py`  
  Preprocesamiento de variables y generaciÃ³n de features relevantes para detecciÃ³n de fraude.

- `comparativa_modelos_RL.py`  
  ComparaciÃ³n entre modelos entrenados con datos originales vs. anonimizados.
---

## ğŸ§  Arquitectura de la SoluciÃ³n â€“ RegresiÃ³n LogÃ­stica

### ğŸ” Pipeline de Procesamiento

```mermaid
graph TD
    A[ğŸ“ Dataset PaySim1] --> B[ğŸ›¡ï¸ SeudonimizaciÃ³n (SHA-256)]
    B --> C[ğŸ”’ K-Anonimato (k=10)]
    C --> D[ğŸ¯ L-Diversidad (l=2)]
    D --> E[ğŸ§ª EvaluaciÃ³n de privacidad (Îµ=2.0)]
    E --> F[ğŸ“Š Preprocesamiento RL]
    F --> G[ğŸ“‰ Entrenamiento RL]
    G --> H[ğŸ“œ EvaluaciÃ³n GDPR]
    H --> I[ğŸ“ VisualizaciÃ³n e InterpretaciÃ³n]

    Preprocesamiento RL: OneHotEncoding, normalizaciÃ³n, eliminaciÃ³n de outliers, split 80/20.

    Entrenamiento RL: Scikit-learn / statsmodels, penalizaciÃ³n, AUC, matriz de confusiÃ³n.

    EvaluaciÃ³n GDPR: simulaciÃ³n de reidentificaciÃ³n y anÃ¡lisis post-anonimizaciÃ³n.
---
### ğŸ“ˆ Resultados Principales: RegresiÃ³n LogÃ­stica

ComparaciÃ³n entre el modelo entrenado con datos originales vs. datos anonimizados:

| MÃ©trica      | Original | Anonimizado | Impacto  | InterpretaciÃ³n            |
|-------------|----------|-------------|----------|---------------------------|
| PrecisiÃ³n   | 99.91%   | 99.91%      | Â±0.00%   | âœ… Estabilidad total       |
| Sensibilidad| 39.45%   | 41.68%      | +2.23%   | ğŸŸ¢ Ligera mejora inesperada |
| F1-Score    | 52.46%   | 54.86%      | +2.40%   | ğŸŸ¢ OptimizaciÃ³n emergente |

**ğŸŸ¢ Fortalezas:**

- *Mejora tras anonimizaciÃ³n*: Se observa un efecto de regularizaciÃ³n implÃ­cita.
- *Interpretabilidad superior*: Modelo simple y explicativo.
- *Cumplimiento normativo*: Buena base para auditorÃ­as con GDPR.

**ğŸ”´ Limitaciones:**

- *Sensibilidad aÃºn baja*: No es ideal como soluciÃ³n Ãºnica en detecciÃ³n de fraude.
- *Modelo lineal*: Menor capacidad para patrones complejos comparado con RF o XGBoost.


---
### ğŸ› ï¸ InstalaciÃ³n y entorno

1. Clona el repositorio:

```bash
git clone https://github.com/tuusuario/TFM_Anonimizacion_RegresionLogistica.git
```

2. Crea el entorno virtual y actÃ­valo:

```bash
python -m venv venv
venv\Scripts\activate    # En Windows
```

3. Instala las dependencias:

```bash
pip install -r requirements.txt
```

---

### ğŸ§ª Reproducibilidad

AsegÃºrate de colocar el archivo `anonimizacion_datos.csv` en la ruta `dataset/`. Luego puedes correr:

```bash
jupyter notebook
```

Y explorar los notebooks dentro de la carpeta `notebooks/`.

---
### ğŸŒ PresentaciÃ³n Interactiva

Accede a la presentaciÃ³n de tu Trabajo Final de MÃ¡ster (TFM) aquÃ­:
ğŸ”— TFM AnonimizaciÃ³n y RegresiÃ³n LogÃ­stica (Genially)

---

### ğŸ‘¨â€ğŸ”¬ Autor

**Alexi Mendoza**  
MÃ¡ster en Big Data & Business Intelligence  
TFM defendido en junio 2025

---

### ğŸ“œ Licencia

Este proyecto es de uso acadÃ©mico. Para usos comerciales o reproducciÃ³n del dataset original, contactar con el autor.